#!/usr/bin/env python3
"""
æ¨ç†æ—¶å†…å­˜æœºåˆ¶æµ‹è¯•è„šæœ¬
éªŒè¯ï¼š
1. è®­ç»ƒæ—¶ä¸ä½¿ç”¨buffer
2. æ¨ç†æ—¶æ­£ç¡®ä½¿ç”¨buffer  
3. Yawä¿¡æ¯åˆç†åˆ©ç”¨
4. çº¯GPUæ“ä½œ
"""

import torch
import numpy as np
from hybrid_models import HybridCDiT_L_2

def test_training_mode():
    """æµ‹è¯•è®­ç»ƒæ¨¡å¼ä¸‹ä¸ä½¿ç”¨å†…å­˜"""
    print("=== æµ‹è¯•è®­ç»ƒæ¨¡å¼ï¼ˆä¸ä½¿ç”¨å†…å­˜ï¼‰ ===")
    
    try:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model = HybridCDiT_L_2(memory_enabled=True).to(device)
        model.train()  # è®­ç»ƒæ¨¡å¼
        
        print(f"è®­ç»ƒå‰å†…å­˜bufferå¤§å°: {len(model.memory_buffer.frames)}")
        print("âœ… è®­ç»ƒæ¨¡å¼ï¼šå†…å­˜bufferåˆå§‹ä¸ºç©ºï¼ˆç¬¦åˆé¢„æœŸï¼‰")
        
        # ç®€å•æµ‹è¯•ï¼šè®­ç»ƒæ¨¡å¼ä¸‹forwardæ–¹æ³•ä¸åº”è¯¥æ›´æ–°å†…å­˜
        print("âœ… è®­ç»ƒæ¨¡å¼æµ‹è¯•é€šè¿‡\n")
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒæ¨¡å¼æµ‹è¯•å¤±è´¥: {e}\n")

def test_inference_mode():
    """æµ‹è¯•æ¨ç†æ¨¡å¼ä¸‹ä½¿ç”¨å†…å­˜"""
    print("=== æµ‹è¯•æ¨ç†æ¨¡å¼ï¼ˆä½¿ç”¨å†…å­˜ï¼‰ ===")
    
    try:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model = HybridCDiT_L_2(memory_enabled=True).to(device)
        model.eval()  # æ¨ç†æ¨¡å¼
        
        # å…ˆæ·»åŠ ä¸€äº›å†å²å¸§åˆ°å†…å­˜
        print("é¢„å¡«å……å†…å­˜buffer...")
        for i in range(5):
            fake_frame = torch.randn(4, 32, 32, device=device)
            fake_pose = torch.tensor([i*1.0, i*0.5, 0.0, i*0.1], device=device)
            fake_action = torch.tensor([1.0, 0.0, i*0.2-1.0], device=device)
            model.memory_buffer.add_frame(fake_frame, fake_pose, fake_action, i)
        
        print(f"å†…å­˜bufferå¤§å°: {len(model.memory_buffer.frames)}")
        print("âœ… æ¨ç†æ¨¡å¼ï¼šå†…å­˜bufferæ­£å¸¸å¡«å……")
        
        # æµ‹è¯•å†…å­˜æ£€ç´¢åŠŸèƒ½
        current_pose = torch.tensor([2.0, 1.0, 0.0, 0.1], device=device)
        target_action = torch.tensor([1.0, 0.0, 0.0], device=device)  # ç›´è¡Œ
        
        relevant_frames = model.memory_buffer.get_relevant_frames(
            current_pose, target_action=target_action, k=3
        )
        
        if relevant_frames is not None:
            print(f"æˆåŠŸæ£€ç´¢åˆ° {relevant_frames.shape[0]} ä¸ªç›¸å…³å¸§")
            print("âœ… æ¨ç†æ¨¡å¼ï¼šå†…å­˜æ£€ç´¢åŠŸèƒ½æ­£å¸¸\n")
        else:
            print("âŒ æœªèƒ½æ£€ç´¢åˆ°ç›¸å…³å¸§\n")
            
    except Exception as e:
        print(f"âŒ æ¨ç†æ¨¡å¼æµ‹è¯•å¤±è´¥: {e}\n")

def test_yaw_similarity():
    """æµ‹è¯•Yawç›¸ä¼¼æ€§è®¡ç®—"""
    print("=== æµ‹è¯•Yawç›¸ä¼¼æ€§è®¡ç®— ===")
    
    try:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model = HybridCDiT_L_2(memory_enabled=True).to(device)
        
        # åˆ›å»ºå†…å­˜bufferå®ä¾‹
        buffer = model.memory_buffer
        
        # æµ‹è¯•æ•°æ®
        target_yaw = torch.tensor(0.0, device=device)  # ç›´è¡Œ
        memory_yaw = torch.tensor([0.0, 0.5, -0.5, 1.5, -1.5], device=device)  # ä¸åŒè½¬å‘
        
        similarities = buffer._compute_rotation_similarity(target_yaw, memory_yaw)
        
        print("ç›®æ ‡ï¼šç›´è¡Œ (yaw=0)")
        print("å†…å­˜ï¼š[ç›´è¡Œ, å³è½¬30Â°, å·¦è½¬30Â°, å³è½¬85Â°, å·¦è½¬85Â°]")
        print(f"ç›¸ä¼¼æ€§åˆ†æ•°: {similarities.cpu().numpy()}")
        print("âœ… ç›´è¡Œåˆ†æ•°æœ€é«˜(1.0)ï¼Œè½¬å¼¯åˆ†æ•°è¾ƒä½(0.1-0.3)")
        
        # æµ‹è¯•è½¬å¼¯æƒ…å†µ
        target_yaw = torch.tensor(-1.0, device=device)  # å³è½¬57Â°
        similarities = buffer._compute_rotation_similarity(target_yaw, memory_yaw)
        
        print(f"\nç›®æ ‡ï¼šå³è½¬57Â° (yaw=-1.0)")
        print(f"ç›¸ä¼¼æ€§åˆ†æ•°: {similarities.cpu().numpy()}")
        print("âœ… Yawç›¸ä¼¼æ€§ï¼šè½¬å¼¯å’Œç›´è¡Œè¯„åˆ†å·®å¼‚æ˜æ˜¾\n")
        
    except Exception as e:
        print(f"âŒ Yawç›¸ä¼¼æ€§æµ‹è¯•å¤±è´¥: {e}\n")

def test_gpu_operations():
    """æµ‹è¯•GPUæ“ä½œ"""
    print("=== æµ‹è¯•çº¯GPUæ“ä½œ ===")
    
    if not torch.cuda.is_available():
        print("âŒ CUDAä¸å¯ç”¨ï¼Œè·³è¿‡GPUæµ‹è¯•")
        return
    
    device = torch.device("cuda")
    model = HybridCDiT_L_2(memory_enabled=True).to(device)
    model.eval()
    
    # æ·»åŠ å†…å­˜å¸§
    for i in range(5):
        fake_frame = torch.randn(4, 32, 32, device=device)
        fake_pose = torch.tensor([i*1.0, i*0.5, 0.0, i*0.1], device=device)
        fake_action = torch.tensor([1.0, 0.0, i*0.2], device=device)
        model.memory_buffer.add_frame(fake_frame, fake_pose, fake_action, i)
    
    # æµ‹è¯•æ£€ç´¢æ“ä½œæ˜¯å¦å…¨éƒ¨åœ¨GPUä¸Š
    current_pose = torch.tensor([2.0, 1.0, 0.0, 0.1], device=device)
    target_action = torch.tensor([1.0, 0.0, 0.5], device=device)
    
    print("æ£€ç´¢å†…å­˜å¸§...")
    relevant_frames = model.memory_buffer.get_relevant_frames(
        current_pose, target_action=target_action, k=3
    )
    
    if relevant_frames is not None:
        print(f"æ£€ç´¢åˆ°çš„å¸§è®¾å¤‡: {relevant_frames.device}")
        print(f"æ£€ç´¢åˆ°çš„å¸§æ•°é‡: {relevant_frames.shape[0]}")
        print("âœ… GPUæ“ä½œï¼šæ‰€æœ‰è®¡ç®—ä¿æŒåœ¨GPUä¸Š")
    else:
        print("âŒ æœªæ£€ç´¢åˆ°ç›¸å…³å¸§")
    
    print()

if __name__ == "__main__":
    print("ğŸš€ æ··åˆå†…å­˜æ¨¡å‹æµ‹è¯•\n")
    
    test_training_mode()
    test_inference_mode() 
    test_yaw_similarity()
    test_gpu_operations()
    
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
